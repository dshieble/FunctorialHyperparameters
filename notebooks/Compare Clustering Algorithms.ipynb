{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from copy import deepcopy\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from hdbscan import HDBSCAN\n",
    "import cluster_combinations\n",
    "import data_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_mnist, y_mnist = rawX, rawy = data_helper.load_mnist(path='../fashion', kind='train')\n",
    "\n",
    "train_bunch = fetch_20newsgroups(subset=\"train\")\n",
    "X_news = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "    ]).fit_transform(train_bunch['data'])\n",
    "y_news = train_bunch['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, news) 10 out of 500 completed. MHDBSCAN Win Ratio: 0.6 Standard Error: 0.15491933384829668\n",
      "(1000, news) 20 out of 500 completed. MHDBSCAN Win Ratio: 0.7 Standard Error: 0.10246950765959599\n",
      "(1000, news) 30 out of 500 completed. MHDBSCAN Win Ratio: 0.7 Standard Error: 0.08366600265340757\n"
     ]
    }
   ],
   "source": [
    "MIN_SAMPLES = 5\n",
    "MIN_CLUSTER_SIZE = 5\n",
    "ALPHA_LIST_SIZE = 5\n",
    "NUM_EXPERIMENTS = 500\n",
    "BOOTSTRAP_SAMPLE_SIZE = 1000\n",
    "\n",
    "def get_experimental_results(X, y, alpha_list):\n",
    "\n",
    "    hdbscan_results_list = []\n",
    "    for alpha in alpha_list:\n",
    "        hdbscan_labels = HDBSCAN(\n",
    "            alpha=alpha,\n",
    "            min_samples=MIN_SAMPLES,\n",
    "            min_cluster_size=MIN_CLUSTER_SIZE,\n",
    "            # Our MHDBSCAN implementation is built on the prims_kdtree algorithm and supports single clusters\n",
    "            algorithm=\"prims_kdtree\",\n",
    "            allow_single_cluster=True\n",
    "        ).fit_predict(X)\n",
    "        hdbscan_score = adjusted_rand_score(y, hdbscan_labels)\n",
    "        hdbscan_results_list.append((hdbscan_labels, hdbscan_score))\n",
    "    (best_hdbscan_labels, best_hdbscan_score) = max(hdbscan_results_list, key=lambda k: k[1])\n",
    "\n",
    "    mhdbscan_labels = cluster_combinations.MultiscaleHDBSCAN(\n",
    "        alpha_list=alpha_list, min_samples=MIN_SAMPLES, min_cluster_size=MIN_CLUSTER_SIZE).fit_predict(X)\n",
    "    mhdbscan_score = adjusted_rand_score(y, mhdbscan_labels)\n",
    "    return best_hdbscan_score, mhdbscan_score\n",
    "\n",
    "for dataset_name, X_full, y_full in [(\"news\", X_news, y_news), (\"mnist\", X_mnist, y_mnist)]:\n",
    "    num_hbscan_is_better, num_mhbscan_is_better = 0, 0\n",
    "    while num_mhbscan_is_better + num_hbscan_is_better < NUM_EXPERIMENTS:\n",
    "\n",
    "        # Bootstrap samples by randomly choosing a dataset and region of alpha hyperparameters\n",
    "        indices = np.random.permutation(range(X_full.shape[0]))[:BOOTSTRAP_SAMPLE_SIZE]\n",
    "        alpha_list = np.random.choice(np.linspace(0.001, 3, 1000), ALPHA_LIST_SIZE)\n",
    "\n",
    "        X = TruncatedSVD(random_state=0).fit_transform(X_full[indices])\n",
    "        y = y_full[indices]\n",
    "        try:\n",
    "            hdbscan_score, mhdbscan_score = get_experimental_results(\n",
    "                X=X, y=y, alpha_list=alpha_list)\n",
    "        except ValueError as e:\n",
    "            # Skip alphas where all trees in the condensed_trees list have no clusters\n",
    "            continue\n",
    "        if mhdbscan_score > hdbscan_score:\n",
    "            num_mhbscan_is_better += 1\n",
    "        elif hdbscan_score > mhdbscan_score:\n",
    "            num_hbscan_is_better += 1\n",
    "        total_experiments = num_mhbscan_is_better + num_hbscan_is_better\n",
    "        if (total_experiments > 0) and (total_experiments % 10 == 0):\n",
    "            win_ratio = num_mhbscan_is_better / total_experiments\n",
    "            standard_error = np.sqrt((win_ratio*(1-win_ratio)) / total_experiments)\n",
    "            print(\"({}, {}) {} out of {} completed. MHDBSCAN Win Ratio: {} Standard Error: {}\".format(\n",
    "                BOOTSTRAP_SAMPLE_SIZE,\n",
    "                dataset_name,\n",
    "                total_experiments,\n",
    "                NUM_EXPERIMENTS,\n",
    "                win_ratio,\n",
    "                standard_error))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
