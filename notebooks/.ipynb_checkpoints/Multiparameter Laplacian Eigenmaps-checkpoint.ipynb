{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import spectral_embedding, MDS, SpectralEmbedding\n",
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "from scipy.spatial.distance import cdist \n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "from numba import types\n",
    "from numba.typed import Dict\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from matplotlib.colors import BASE_COLORS\n",
    "from helpers import (\n",
    "    mds, write_embedding_to_text_file, write_embedding_to_two_text_files, is_numeric, fit_laplacian_eigenmaps\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.manifold import SpectralEmbedding \n",
    "from sklearn.metrics.pairwise import rbf_kernel, euclidean_distances\n",
    "\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context='talk',font_scale=0.7)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import vstack \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def get_news_dataset():\n",
    "    train_bunch = fetch_20newsgroups(subset=\"train\")\n",
    "    test_bunch = fetch_20newsgroups(subset=\"test\")\n",
    "    raw_Xtrain, raw_ytrain = train_bunch['data'], train_bunch['target']\n",
    "    raw_Xtest, raw_ytest = test_bunch['data'], test_bunch['target']\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('svd', TruncatedSVD(n_components=500)),\n",
    "    ])\n",
    "\n",
    "    raw_Xtrain = raw_Xtrain[::3]\n",
    "    raw_Xtest = raw_Xtest[::3]\n",
    "    raw_ytrain = raw_ytrain[::3]\n",
    "    raw_ytest = raw_ytest[::3]\n",
    "    rawX = raw_Xtrain + raw_Xtest\n",
    "    rawX = pipeline.fit_transform(rawX)\n",
    "    raw_Xtrain, raw_Xtest = rawX[:len(raw_ytrain)], rawX[len(raw_ytrain):]\n",
    "    return rawX, raw_Xtrain, raw_ytrain, raw_Xtest, raw_ytest\n",
    "\n",
    "def get_mnist_dataset():\n",
    "    raw_Xtrain, raw_ytrain = load_mnist('data/fashion', kind='train')\n",
    "    raw_Xtest, raw_ytest = load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "    raw_Xtrain = raw_Xtrain[::3]\n",
    "    raw_Xtest = raw_Xtest[::3]\n",
    "    raw_ytrain = raw_ytrain[::3]\n",
    "    raw_ytest = raw_ytest[::3]\n",
    "    rawX = np.vstack((raw_Xtrain, raw_Xtest))\n",
    "    return rawX, raw_Xtrain, raw_ytrain, raw_Xtest, raw_ytest\n",
    "\n",
    "\n",
    "dataset_fn_dict = {\n",
    "    \"news\": get_news_dataset,\n",
    "    \"mnist\": get_mnist_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.distances as dist\n",
    "from sklearn.manifold import SpectralEmbedding \n",
    "\n",
    "\n",
    "\n",
    "def get_pca_embeddings(rawX, train_count, n_components):\n",
    "    raw_pca_embeddings = PCA(n_components=n_components).fit_transform(rawX)\n",
    "    pca_embeddings = Normalizer().fit_transform(raw_pca_embeddings)\n",
    "    train_pca_embeddings = pca_embeddings[:train_count]\n",
    "    test_pca_embeddings = pca_embeddings[train_count:]  \n",
    "    return train_pca_embeddings, test_pca_embeddings\n",
    "\n",
    "\n",
    "def get_le_embeddings(rawX, train_count, n_components, alpha):\n",
    "    assert alpha >= 0 and alpha <= 1.0\n",
    "    kernelized_distances = rbf_kernel(raw_Xtrain, raw_Xtrain, gamma=1.0)\n",
    "    kernelized_distances = kernelized_distances * (kernelized_distances >= alpha)\n",
    "    embeddings = SpectralEmbedding(\n",
    "        n_components=n_components,\n",
    "        affinity=\"precomputed\").fit_transform(kernelized_distances)\n",
    "\n",
    "    embeddings = Normalizer().fit_transform(embeddings)\n",
    "    train_embeddings = embeddings[:train_count]\n",
    "    test_embeddings = embeddings[train_count:]\n",
    "    return train_embeddings, test_embeddings\n",
    "\n",
    "\n",
    "def get_msle_embeddings(rawX, train_count, n_components):\n",
    "    kernelized_distances = rbf_kernel(raw_Xtrain, raw_Xtrain, gamma=1.0)**2\n",
    "    embeddings = SpectralEmbedding(\n",
    "        n_components=n_components,\n",
    "        affinity=\"precomputed\").fit_transform(kernelized_distances)\n",
    "    embeddings = Normalizer().fit_transform(embeddings)\n",
    "    train_embeddings = embeddings[:train_count]\n",
    "    test_embeddings = embeddings[train_count:]\n",
    "    return train_embeddings, test_embeddings\n",
    "\n",
    "\n",
    "\n",
    "def train_model(Xtrain, ytrain, Xtest, ytest):\n",
    "    results = {}\n",
    "    for name, model in [(\"KNeighborsClassifier\", KNeighborsClassifier(n_neighbors=5))]:\n",
    "        model.fit(Xtrain, ytrain)\n",
    "        results[name] = {}\n",
    "\n",
    "        encoder = OneHotEncoder()\n",
    "        encoder.fit(ytrain[:, None])\n",
    "        results[name][\"train_score\"] = roc_auc_score(\n",
    "            encoder.transform(ytrain[:, None]).todense(),\n",
    "            encoder.transform(model.predict(Xtrain)[:, None]).todense())\n",
    "\n",
    "        results[name][\"test_score\"] = roc_auc_score(\n",
    "            encoder.transform(ytest[:, None]).todense(),\n",
    "            encoder.transform(model.predict(Xtest)[:, None]).todense())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the n x n matrix W \n",
    "# W_ij = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent? \n",
    "# https://medium.com/swlh/euclidean-distance-matrix-4c3e1378d87f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
