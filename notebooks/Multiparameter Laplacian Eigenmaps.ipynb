{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import spectral_embedding, MDS, SpectralEmbedding\n",
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "from scipy.spatial.distance import cdist \n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "from numba import types\n",
    "from numba.typed import Dict\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from matplotlib.colors import BASE_COLORS\n",
    "from helpers import (\n",
    "    mds, write_embedding_to_text_file, write_embedding_to_two_text_files, is_numeric, fit_laplacian_eigenmaps\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.manifold import SpectralEmbedding \n",
    "from sklearn.metrics.pairwise import rbf_kernel, euclidean_distances\n",
    "\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context='talk',font_scale=0.7)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import vstack \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def get_news_dataset(subsample):\n",
    "    print(\"fetching news with subsample {}\".format(subsample))\n",
    "    train_bunch = fetch_20newsgroups(subset=\"train\")\n",
    "    test_bunch = fetch_20newsgroups(subset=\"test\")\n",
    "    raw_Xtrain, raw_ytrain = train_bunch['data'], train_bunch['target']\n",
    "    raw_Xtest, raw_ytest = test_bunch['data'], test_bunch['target']\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('svd', TruncatedSVD(n_components=500)),\n",
    "    ])\n",
    "\n",
    "    raw_Xtrain = raw_Xtrain[::subsample]\n",
    "    raw_Xtest = raw_Xtest[::subsample]\n",
    "    raw_ytrain = raw_ytrain[::subsample]\n",
    "    raw_ytest = raw_ytest[::subsample]\n",
    "    rawX = raw_Xtrain + raw_Xtest\n",
    "    rawX = pipeline.fit_transform(rawX)\n",
    "    raw_Xtrain, raw_Xtest = rawX[:len(raw_ytrain)], rawX[len(raw_ytrain):]\n",
    "    return rawX, raw_Xtrain, raw_ytrain, raw_Xtest, raw_ytest\n",
    "\n",
    "def get_mnist_dataset(subsample):\n",
    "    print(\"fetching mnist with subsample {}\".format(subsample))\n",
    "    raw_Xtrain, raw_ytrain = load_mnist('data/fashion', kind='train')\n",
    "    raw_Xtest, raw_ytest = load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "    raw_Xtrain = raw_Xtrain[::subsample]\n",
    "    raw_Xtest = raw_Xtest[::subsample]\n",
    "    raw_ytrain = raw_ytrain[::subsample]\n",
    "    raw_ytest = raw_ytest[::subsample]\n",
    "    rawX = np.vstack((raw_Xtrain, raw_Xtest))\n",
    "    return rawX, raw_Xtrain, raw_ytrain, raw_Xtest, raw_ytest\n",
    "\n",
    "\n",
    "dataset_fn_dict = {\n",
    "    \"news\": get_news_dataset,\n",
    "    \"mnist\": get_mnist_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.distances as dist\n",
    "from sklearn.manifold import SpectralEmbedding \n",
    "\n",
    "\n",
    "\n",
    "def get_pca_embeddings(rawX, train_count, n_components):\n",
    "    raw_pca_embeddings = PCA(n_components=n_components).fit_transform(rawX)\n",
    "    pca_embeddings = Normalizer().fit_transform(raw_pca_embeddings)\n",
    "    train_pca_embeddings = pca_embeddings[:train_count]\n",
    "    test_pca_embeddings = pca_embeddings[train_count:]  \n",
    "    return train_pca_embeddings, test_pca_embeddings\n",
    "\n",
    "\n",
    "def get_le_embeddings(rawX, train_count, n_components, alpha):\n",
    "    assert alpha >= 0 and alpha <= 1.0\n",
    "    kernelized_distances = rbf_kernel(rawX, rawX, gamma=1.0)\n",
    "    kernelized_distances = kernelized_distances * (kernelized_distances >= alpha)\n",
    "    print(kernelized_distances.shape)\n",
    "    embeddings = SpectralEmbedding(\n",
    "        n_components=n_components,\n",
    "        affinity=\"precomputed\").fit_transform(kernelized_distances)\n",
    "\n",
    "    embeddings = Normalizer().fit_transform(embeddings)\n",
    "    train_embeddings = embeddings[:train_count]\n",
    "    test_embeddings = embeddings[train_count:]\n",
    "    return train_embeddings, test_embeddings\n",
    "\n",
    "\n",
    "def get_msle_embeddings(rawX, train_count, n_components):\n",
    "    kernelized_distances = rbf_kernel(rawX, rawX, gamma=1.0)**2\n",
    "    embeddings = SpectralEmbedding(\n",
    "        n_components=n_components,\n",
    "        affinity=\"precomputed\").fit_transform(kernelized_distances)\n",
    "    embeddings = Normalizer().fit_transform(embeddings)\n",
    "    train_embeddings = embeddings[:train_count]\n",
    "    test_embeddings = embeddings[train_count:]\n",
    "    return train_embeddings, test_embeddings\n",
    "\n",
    "\n",
    "\n",
    "def train_model(Xtrain, ytrain, Xtest, ytest):\n",
    "    results = {}\n",
    "    for name, model in [(\"KNeighborsClassifier\", KNeighborsClassifier(n_neighbors=5))]:\n",
    "        model.fit(Xtrain, ytrain)\n",
    "        results[name] = {}\n",
    "\n",
    "        encoder = OneHotEncoder()\n",
    "        encoder.fit(ytrain[:, None])\n",
    "        results[name][\"train_score\"] = roc_auc_score(\n",
    "            encoder.transform(ytrain[:, None]).todense(),\n",
    "            encoder.transform(model.predict(Xtrain)[:, None]).todense())\n",
    "\n",
    "        results[name][\"test_score\"] = roc_auc_score(\n",
    "            encoder.transform(ytest[:, None]).todense(),\n",
    "            encoder.transform(model.predict(Xtest)[:, None]).todense())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "news\n",
      "==========================\n",
      "fetching news with subsample 20\n",
      "rawX.shape (943, 500)\n",
      "==========================\n",
      "alpha: 0.0\n",
      "(943, 943)\n",
      "alpha: 0.1\n",
      "(943, 943)\n",
      "alpha: 0.2\n",
      "(943, 943)\n",
      "alpha: 0.30000000000000004\n",
      "(943, 943)\n",
      "alpha: 0.4\n",
      "(943, 943)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.5\n",
      "(943, 943)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.6000000000000001\n",
      "(943, 943)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.7000000000000001\n",
      "(943, 943)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.8\n",
      "(943, 943)\n",
      "alpha: 0.9\n",
      "(943, 943)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms\n",
      "n_components: 25\n",
      "0.0 {'KNeighborsClassifier': {'train_score': 0.7963953219243589, 'test_score': 0.6796517256572848}}\n",
      "0.1 {'KNeighborsClassifier': {'train_score': 0.7963953219243589, 'test_score': 0.6796517256572848}}\n",
      "0.2 {'KNeighborsClassifier': {'train_score': 0.7184980573493537, 'test_score': 0.6037529272846317}}\n",
      "0.30000000000000004 {'KNeighborsClassifier': {'train_score': 0.6749833937305844, 'test_score': 0.5289046401035019}}\n",
      "0.4 {'KNeighborsClassifier': {'train_score': 0.6852445427800592, 'test_score': 0.5472902436952369}}\n",
      "0.5 {'KNeighborsClassifier': {'train_score': 0.6678447163261889, 'test_score': 0.5436583671176796}}\n",
      "0.6000000000000001 {'KNeighborsClassifier': {'train_score': 0.6593010132076905, 'test_score': 0.5260637127535143}}\n",
      "0.7000000000000001 {'KNeighborsClassifier': {'train_score': 0.6451489675179598, 'test_score': 0.4962282710139454}}\n",
      "0.8 {'KNeighborsClassifier': {'train_score': 0.6312945880203802, 'test_score': 0.4991958160695728}}\n",
      "0.9 {'KNeighborsClassifier': {'train_score': 0.6145235659293118, 'test_score': 0.49725470726642645}}\n",
      "ms {'KNeighborsClassifier': {'train_score': 0.6145235659293118, 'test_score': 0.49725470726642645}}\n",
      "iteration time: 10.638845205307007\n",
      "==========================\n",
      "mnist\n",
      "==========================\n",
      "fetching mnist with subsample 20\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/fashion/train-labels-idx1-ubyte.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1a41f3ff9740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==========================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mrawX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_Xtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_ytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_Xtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_ytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rawX.shape {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-eaf9e468d1df>\u001b[0m in \u001b[0;36mget_mnist_dataset\u001b[0;34m(subsample)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_mnist_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fetching mnist with subsample {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mraw_Xtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_ytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/fashion'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mraw_Xtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_ytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/fashion'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m't10k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-be2db42c2725>\u001b[0m in \u001b[0;36mload_mnist\u001b[0;34m(path, kind)\u001b[0m\n\u001b[1;32m     58\u001b[0m                                % kind)\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlbpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n\u001b[1;32m     62\u001b[0m                                offset=8)\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/fashion/train-labels-idx1-ubyte.gz'"
     ]
    }
   ],
   "source": [
    "subsample = 20\n",
    "all_n_components = [25]\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name, dataset_fn in dataset_fn_dict.items():\n",
    "    print(\"==========================\")\n",
    "    print(dataset_name)\n",
    "    print(\"==========================\")\n",
    "    rawX, raw_Xtrain, raw_ytrain, raw_Xtest, raw_ytest = dataset_fn(subsample)\n",
    "    print(\"rawX.shape {}\".format(rawX.shape))\n",
    "\n",
    "    all_results[dataset_name] = {}\n",
    "    for n_components in all_n_components:\n",
    "        start = time.time()\n",
    "        print(\"==========================\")\n",
    "        result = {}\n",
    "        \n",
    "        for alpha in np.arange(0,1.0,0.1):\n",
    "            print(\"alpha: {}\".format(alpha))\n",
    "            train_le_embeddings, test_le_embeddings = get_le_embeddings(\n",
    "                rawX=rawX,\n",
    "                train_count=raw_Xtrain.shape[0],\n",
    "                n_components=n_components,\n",
    "                alpha=alpha)\n",
    "            result[alpha] = train_model(\n",
    "                Xtrain=train_le_embeddings,\n",
    "                ytrain=raw_ytrain,\n",
    "                Xtest=test_le_embeddings,\n",
    "                ytest=raw_ytest)\n",
    "\n",
    "        print(\"ms\")\n",
    "        train_msle_embeddings, test_msle_embeddings = get_msle_embeddings(\n",
    "                rawX=rawX,\n",
    "                train_count=raw_Xtrain.shape[0],\n",
    "                n_components=n_components)\n",
    "        result[\"ms\"] = train_model(\n",
    "            Xtrain=train_le_embeddings,\n",
    "            ytrain=raw_ytrain,\n",
    "            Xtest=test_le_embeddings,\n",
    "            ytest=raw_ytest)\n",
    "\n",
    "        print(\"n_components: {}\".format(n_components))\n",
    "        for k, v in result.items():\n",
    "            print(k, v)\n",
    "\n",
    "        all_results[dataset_name][n_components] = result\n",
    "        print(\"iteration time: {}\".format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the n x n matrix W \n",
    "# W_ij = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent? \n",
    "# https://medium.com/swlh/euclidean-distance-matrix-4c3e1378d87f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
